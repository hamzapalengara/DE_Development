{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1325645-3455-4e5c-adad-42278781e65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"/mnt/c/Users/HP/Learning/DE_Development\" not in sys.path:\n",
    "    sys.path.append(\"/mnt/c/Users/HP/Learning/DE_Development\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b6217b3-7771-44eb-bfec-d966bc2341e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/HP/Learning/DE_Development\n",
      "/mnt/c/Users/HP/Learning/DE_Development/data/landing/batch/daily_sales_20240115.csv\n",
      "/mnt/c/Users/HP/Learning/DE_Development/data/bronze/sales\n",
      "+--------------+----------+----------+--------+--------+------------+--------------+------+\n",
      "|transaction_id|      date|product_id|store_id|quantity|total_amount|payment_method|region|\n",
      "+--------------+----------+----------+--------+--------+------------+--------------+------+\n",
      "|        TXN001|15-01-2024|      P001|    S101|       5|      1225.0|   Credit Card| North|\n",
      "|        TXN002|15-01-2024|      P002|    S102|       3|       555.0|          Cash| South|\n",
      "|        TXN003|15-01-2024|      P004|    S101|      10|       280.0|           UPI| North|\n",
      "|        TXN004|15-01-2024|      P001|    S103|       2|       490.0|    Debit Card|  West|\n",
      "|        TXN005|15-01-2024|      P005|    S104|       8|       960.0|           UPI|  East|\n",
      "+--------------+----------+----------+--------+--------+------------+--------------+------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'product_bronze' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 59\u001b[39m\n\u001b[32m     54\u001b[39m dq_conditions = required_cols + [(F.col(\u001b[33m\"\u001b[39m\u001b[33mquantity\u001b[39m\u001b[33m\"\u001b[39m).isNull()) | (F.col(\u001b[33m\"\u001b[39m\u001b[33mtotal_amount\u001b[39m\u001b[33m\"\u001b[39m) >= F.lit(\u001b[32m0.0\u001b[39m))]\n\u001b[32m     55\u001b[39m dq_valid = (F.col(\u001b[33m\"\u001b[39m\u001b[33mtransaction_id\u001b[39m\u001b[33m\"\u001b[39m).isNotNull() & \n\u001b[32m     56\u001b[39m             F.col(\u001b[33m\"\u001b[39m\u001b[33mproduct_id\u001b[39m\u001b[33m\"\u001b[39m).isNotNull() & \n\u001b[32m     57\u001b[39m             ((F.col(\u001b[33m\"\u001b[39m\u001b[33mquantity\u001b[39m\u001b[33m\"\u001b[39m).isNull()) | (F.col(\u001b[33m\"\u001b[39m\u001b[33mtotal_amount\u001b[39m\u001b[33m\"\u001b[39m) >= F.lit(\u001b[32m0.0\u001b[39m))))\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m sales_bronze = \u001b[43mproduct_bronze\u001b[49m.withColumn(\u001b[33m\"\u001b[39m\u001b[33mdq_is_valid\u001b[39m\u001b[33m\"\u001b[39m, dq_valid)\n\u001b[32m     62\u001b[39m sales_bronze.show(\u001b[32m5\u001b[39m, truncate = \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     65\u001b[39m (sales_bronze\n\u001b[32m     66\u001b[39m   .repartition(\u001b[32m1\u001b[39m)\n\u001b[32m     67\u001b[39m   .write\n\u001b[32m     68\u001b[39m   .mode(\u001b[33m\"\u001b[39m\u001b[33moverwrite\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     69\u001b[39m   .partitionBy(\u001b[33m\"\u001b[39m\u001b[33mbatch_date\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     70\u001b[39m   .parquet(bronze_sales_path))\n",
      "\u001b[31mNameError\u001b[39m: name 'product_bronze' is not defined"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F, types as T\n",
    "from pyspark.sql import SparkSession\n",
    "import yaml, os, sys\n",
    "from src.utils.spark_utils import create_spark\n",
    "\n",
    "\n",
    "    \n",
    "config_path = '/mnt/c/Users/HP/Learning/DE_Development/config/pipeline_config_wsl.yaml'\n",
    "\n",
    "with open(config_path, \"r\") as f:\n",
    "    config_file = yaml.safe_load(f)\n",
    "\n",
    "base_path = config_file[\"paths\"][\"base_path\"]\n",
    "print(base_path)\n",
    "landing_batch = config_file[\"paths\"][\"landing\"][\"batch\"].replace(\"${paths.base_path}\", base_path)\n",
    "landing_batch_sales = os.path.join(landing_batch, \"daily_sales_20240115.csv\")\n",
    "print(landing_batch_sales)\n",
    "bronze_sales_path = config_file[\"paths\"][\"bronze\"][\"sales\"].replace(\"${paths.base_path}\", base_path)\n",
    "print(bronze_sales_path)\n",
    "\n",
    "spark = create_spark(config_file[\"spark\"][\"app_name\"], config_file[\"spark\"][\"configs\"])\n",
    "\n",
    "\n",
    "\n",
    "# Define schema matching your actual columns\n",
    "sales_schema = T.StructType([\n",
    "    T.StructField(\"transaction_id\", T.StringType(), True),\n",
    "    T.StructField(\"date\", T.StringType(), True),\n",
    "    T.StructField(\"product_id\", T.StringType(), True),\n",
    "    T.StructField(\"store_id\", T.StringType(), True),\n",
    "    T.StructField(\"quantity\", T.IntegerType(), True),\n",
    "    T.StructField(\"total_amount\", T.DoubleType(), True),\n",
    "    T.StructField(\"payment_method\", T.StringType(), True),  # Keep as string, convert later\n",
    "    T.StructField(\"region\", T.StringType(), True),\n",
    "])\n",
    "\n",
    "\n",
    "sales_raw = (spark.read\n",
    "    .option(\"header\", True)\n",
    "    .schema(sales_schema)\n",
    "    .csv(landing_batch_sales))\n",
    "sales_raw.show(5)\n",
    "\n",
    "\n",
    "\n",
    "sales_bronze = (sales_raw\n",
    "                  .withColumn(\"ingestion_timestamp\", F.current_timestamp())\n",
    "                  .withColumn(\"source_file\", F.input_file_name())\n",
    "                  .withColumn(\"batch_date\", F.current_date())\n",
    "                  .withColumn(\"record_hash\", F.sha2(F.concat_ws(\"||\", *[F.coalesce(F.col(c).cast(\"string\"), F.lit(\"\")) for c in sales_raw.columns]), 256)))\n",
    "\n",
    "# Basic DQ: required fields not null, positive price\n",
    "required_cols = [F.col(\"transaction_id\").isNotNull(), F.col(\"product_id\").isNotNull()]\n",
    "dq_conditions = required_cols + [(F.col(\"quantity\").isNull()) | (F.col(\"total_amount\") >= F.lit(0.0))]\n",
    "dq_valid = (F.col(\"transaction_id\").isNotNull() & \n",
    "            F.col(\"product_id\").isNotNull() & \n",
    "            ((F.col(\"quantity\").isNull()) | (F.col(\"total_amount\") >= F.lit(0.0))))\n",
    "\n",
    "sales_bronze = sales_bronze.withColumn(\"dq_is_valid\", dq_valid)\n",
    "\n",
    "\n",
    "sales_bronze.show(5, truncate = False)\n",
    "\n",
    "\n",
    "(sales_bronze\n",
    "  .repartition(1)\n",
    "  .write\n",
    "  .mode(\"overwrite\")\n",
    "  .partitionBy(\"batch_date\")\n",
    "  .parquet(bronze_sales_path))\n",
    "\n",
    "# Read the written Parquet data back\n",
    "bronze_sales_read = spark.read.parquet(bronze_sales_path)\n",
    "print(\"=== BRONZE DATA READ BACK ===\")\n",
    "bronze_sales_read.show(10, truncate=False)\n",
    "print(f\"Total rows in bronze: {bronze_sales_read.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fb09d8-6a2c-4e61-9d98-4a2edf784224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
